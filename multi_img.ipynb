{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_img.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxgxggIWgoQf",
        "outputId": "65539e30-aee6-41d3-af78-e584151ac682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuMn8pMZCI6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b4609e-b433-4bb5-badc-f4eecce485ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "target=[]\n",
        "image=[]\n",
        "flat_data=[]\n",
        "\n",
        "DATADIR='/content/drive/MyDrive/DATASET_UPDATED(50)'\n",
        "catagories=['Aadhar card', 'Driving license', 'Pan card']\n",
        "\n",
        "for c in catagories:\n",
        "    class_num=catagories.index(c)\n",
        "    path=os.path.join(DATADIR,c)\n",
        "    for img in os.listdir(path):\n",
        "      img_array=imread(os.path.join(path,img))\n",
        "      #print(img_array)\n",
        "      img_resized=resize(img_array,(150,150,3))\n",
        "      flat_data.append(img_resized.flatten())\n",
        "      image.append(img_resized)\n",
        "      target.append(class_num)\n",
        "    \n",
        "flat_data=np.array(flat_data)\n",
        "target=np.array(target)\n",
        "image=np.array(image)\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into training and testing \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(flat_data,target,test_size=0.1,random_state=109)\n"
      ],
      "metadata": {
        "id": "ySXWGsKYCk87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import svm\n",
        "param_grid=[\n",
        "            {'C':[1,10,100,1000],'kernel':['linear']},\n",
        "            {'C':[1,10,100,1000],'gamma':[0.001,0.0001],'kernel':['rbf']},\n",
        "]\n",
        "svc=svm.SVC(probability=True)\n",
        "clf=GridSearchCV(svc,param_grid)\n",
        "clf.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "FVG-t6KjCn7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54dc650c-c66e-437b-c6fc-663950fa64de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVC(probability=True),\n",
              "             param_grid=[{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
              "                         {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
              "                          'kernel': ['rbf']}])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=clf.predict(x_test)\n",
        "y_pred\n",
        "y_test\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "accuracy_score(y_pred,y_test)"
      ],
      "metadata": {
        "id": "yy0PYfhLCqjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f7cb6c2-0258-4f0d-dbcd-e909e743b0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "pickle.dump(clf,open('img_model.p','wb'))\n",
        "model=pickle.load(open('img_model.p','rb'))"
      ],
      "metadata": {
        "id": "hsaP-jsACxH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "\n",
        "!pip install easyocr\n",
        "!pip install opencv-python-headless==4.1.2.30\n",
        "\n",
        "!pip install db-sqlite3\n",
        "\n",
        "!apt install libzbar0\n",
        "!pip install pyzbar"
      ],
      "metadata": {
        "id": "bPNfroXQCzCW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90a14bf3-810f-4d05-cc0f-4d9464a13d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.8.1-py2.py3-none-any.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.4.0)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.3.5)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.13.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit) (6.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.11.3)\n",
            "Collecting watchdog\n",
            "  Downloading watchdog-2.1.7-py3-none-manylinux2014_x86_64.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.10.0.2)\n",
            "Collecting blinker\n",
            "  Downloading blinker-1.4.tar.gz (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n",
            "Collecting gitpython!=3.1.19\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.0)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 30.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
            "Collecting validators\n",
            "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
            "Collecting pympler>=0.9\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.21.5)\n",
            "Requirement already satisfied: click<8.1,>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->streamlit) (3.7.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n",
            "Collecting ipykernel>=5.1.2\n",
            "  Downloading ipykernel-6.11.0-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.7.0)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.1.1)\n",
            "Collecting setuptools>=60\n",
            "  Downloading setuptools-61.3.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Collecting ipython>=7.23.1\n",
            "  Downloading ipython-7.32.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 46.2 MB/s \n",
            "\u001b[?25hCollecting jupyter-client>=6.1.12\n",
            "  Downloading jupyter_client-7.2.1-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.1.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.4.8)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.5.4)\n",
            "Collecting tornado>=5.0\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[K     |████████████████████████████████| 428 kB 39.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[K     |████████████████████████████████| 380 kB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.6.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: pyzmq>=22.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (22.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.9.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.8.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (3.0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Building wheels for collected packages: blinker\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13478 sha256=229455ead96a1d7b749263e3b772832c81bb320466c7a99d451652f289747c35\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n",
            "Successfully built blinker\n",
            "Installing collected packages: tornado, setuptools, prompt-toolkit, jupyter-client, ipython, ipykernel, smmap, gitdb, watchdog, validators, toml, pympler, pydeck, gitpython, blinker, streamlit\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.28 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.11.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed blinker-1.4 gitdb-4.0.9 gitpython-3.1.27 ipykernel-6.11.0 ipython-7.32.0 jupyter-client-7.2.1 prompt-toolkit-3.0.28 pydeck-0.7.1 pympler-1.0.1 setuptools-61.3.0 smmap-5.0.0 streamlit-1.8.1 toml-0.10.2 tornado-6.1 validators-0.18.2 watchdog-2.1.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "ipykernel",
                  "jupyter_client",
                  "pkg_resources",
                  "prompt_toolkit",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.4.1-py3-none-any.whl (63.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 63.6 MB 56 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.21.5)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.11.1+cu111)\n",
            "Requirement already satisfied: Pillow<8.3.0 in /usr/local/lib/python3.7/dist-packages (from easyocr) (7.1.2)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from easyocr) (3.13)\n",
            "Collecting python-bidi\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->easyocr) (3.10.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from python-bidi->easyocr) (1.15.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (3.0.7)\n",
            "Installing collected packages: python-bidi, opencv-python-headless, easyocr\n",
            "Successfully installed easyocr-1.4.1 opencv-python-headless-4.5.5.64 python-bidi-0.4.2\n",
            "Collecting opencv-python-headless==4.1.2.30\n",
            "  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.5.5.64\n",
            "    Uninstalling opencv-python-headless-4.5.5.64:\n",
            "      Successfully uninstalled opencv-python-headless-4.5.5.64\n",
            "Successfully installed opencv-python-headless-4.1.2.30\n",
            "Collecting db-sqlite3\n",
            "  Downloading db-sqlite3-0.0.1.tar.gz (1.4 kB)\n",
            "Collecting db\n",
            "  Downloading db-0.1.1.tar.gz (3.4 kB)\n",
            "Collecting antiorm\n",
            "  Downloading antiorm-1.2.1.tar.gz (171 kB)\n",
            "\u001b[K     |████████████████████████████████| 171 kB 5.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: db-sqlite3, db, antiorm\n",
            "  Building wheel for db-sqlite3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for db-sqlite3: filename=db_sqlite3-0.0.1-py3-none-any.whl size=1794 sha256=c7919ddf96e1793b737f27221a96347524ad75760136b1054a8c2ba1ec4be250\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/38/d5/2f54461050571bf5330fee2a37ab1c9b5e7540b0572f1acdab\n",
            "  Building wheel for db (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for db: filename=db-0.1.1-py3-none-any.whl size=3895 sha256=21cb33b936ad0fd00c8f50fc9eedcf48001433f693d1a3bce3ff7a89ea0af3f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/97/82/741d2b360507411ec233d0280d7371faa94b03bde834e4a9be\n",
            "  Building wheel for antiorm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antiorm: filename=antiorm-1.2.1-py3-none-any.whl size=31679 sha256=6d238373afb302bbf3c48883086d098797860bd05889a1a5e3fd0bd6c3d4725d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/43/70/e9729370cfff40c49d3e3d05377d54b3ecd71f64e62341ea80\n",
            "Successfully built db-sqlite3 db antiorm\n",
            "Installing collected packages: antiorm, db, db-sqlite3\n",
            "Successfully installed antiorm-1.2.1 db-0.1.1 db-sqlite3-0.0.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libv4l-0 libv4lconvert0\n",
            "The following NEW packages will be installed:\n",
            "  libv4l-0 libv4lconvert0 libzbar0\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 193 kB of archives.\n",
            "After this operation, 760 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libv4lconvert0 amd64 1.14.2-1 [76.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libv4l-0 amd64 1.14.2-1 [41.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libzbar0 amd64 0.10+doc-10.1build2 [75.7 kB]\n",
            "Fetched 193 kB in 1s (271 kB/s)\n",
            "Selecting previously unselected package libv4lconvert0:amd64.\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../libv4lconvert0_1.14.2-1_amd64.deb ...\n",
            "Unpacking libv4lconvert0:amd64 (1.14.2-1) ...\n",
            "Selecting previously unselected package libv4l-0:amd64.\n",
            "Preparing to unpack .../libv4l-0_1.14.2-1_amd64.deb ...\n",
            "Unpacking libv4l-0:amd64 (1.14.2-1) ...\n",
            "Selecting previously unselected package libzbar0:amd64.\n",
            "Preparing to unpack .../libzbar0_0.10+doc-10.1build2_amd64.deb ...\n",
            "Unpacking libzbar0:amd64 (0.10+doc-10.1build2) ...\n",
            "Setting up libv4lconvert0:amd64 (1.14.2-1) ...\n",
            "Setting up libv4l-0:amd64 (1.14.2-1) ...\n",
            "Setting up libzbar0:amd64 (0.10+doc-10.1build2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting pyzbar\n",
            "  Downloading pyzbar-0.1.9-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pyzbar\n",
            "Successfully installed pyzbar-0.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import json\n",
        "import easyocr\n",
        "from matplotlib import pyplot as plt\n",
        "import tkinter\n",
        "from tkinter import font\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from PIL import Image\n",
        "import io\n",
        "import streamlit as st\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import pickle\n",
        "import re\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import pyzbar.pyzbar as pyzbar\n",
        "from pyzbar.pyzbar import decode\n",
        "\n",
        "\n",
        "\n",
        "st.title('Document Identification and Verification')\n",
        "page_names = ['Single Image', 'Multi-image File']\n",
        "page = st.radio('Select Option', page_names)\n",
        "if page == 'Single Image':\n",
        "   \n",
        "  model=pickle.load(open('img_model.p','rb'))\n",
        "\n",
        "  your_name = st.text_input(\"Enter your Name\")\n",
        "  #st.title(your_name)\n",
        "  your_no = st.text_input(\"Enter your Document Number\")\n",
        "  #st.title(your_no)\n",
        "  st.text('upload the Image')\n",
        "  uploaded_file= st.file_uploader(\"choose an image...\",type=['jpeg','jpg','png'])\n",
        "\n",
        "  @st.cache(suppress_st_warning=True)\n",
        "  def aa(result,img,your_name,your_no):\n",
        "    decodedObjects = pyzbar.decode(img)\n",
        "    for obj in decodedObjects:\n",
        "      x=list(str(obj.data).split('\"'))\n",
        "      if(obj.type=='QRCODE'):\n",
        "        print(x[7],x[5])\n",
        "    try:\n",
        "      aa_name=x[7]\n",
        "      aa_no=x[5]\n",
        "      if (aa_name==your_name and aa_no==your_no):\n",
        "        aut=\"YES\"\n",
        "        ver=\"YES\"\n",
        "        #st.write(\"Aadhar Name:\"+ aa_name)\n",
        "        #st.write(\"Aadhar no:\"+ aa_no)\n",
        "        df1(aa_name,aa_no,aut,ver)\n",
        "        st.success(\"The Document is Identified as Aadhaar Card and Authenticated successfully...!\")\n",
        "    except:    \n",
        "      spacer = 100\n",
        "      t=''\n",
        "      l=['Unique', 'Identification', 'Authority', 'of', 'India','Solapur', 'North','Father','Near Ram Mandir']\n",
        "      for detection in result: \n",
        "        top_left = tuple(detection[0][0])\n",
        "        bottom_right = tuple(detection[0][2])\n",
        "        text = detection[1]\n",
        "        try:\n",
        "          img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "          img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "        except:\n",
        "          pass\n",
        "        \n",
        "        \n",
        "        spacer+=15\n",
        "        #print(text)\n",
        "\n",
        "        x=text.split(\" \")\n",
        "        c=0\n",
        "        for i in x:\n",
        "          if i in l:\n",
        "            c=1\n",
        "            break\n",
        "        if c==0:\n",
        "          t=t+text+\"\\n\"\n",
        "\n",
        "      aa_pattern=r\"\\d{4}\\s\\d{4}\\s\\d{4}\"\n",
        "      aa_no_=re.search(aa_pattern,t).group()\n",
        "      no=''\n",
        "      for i in aa_no_:\n",
        "        if(i!=\"\\n\" and i!=\" \"):\n",
        "            no=no+i\n",
        "      aa_no=no\n",
        "      #st.write(\"Aadhar Number :\"+ no)\n",
        "\n",
        "\n",
        "      try:\n",
        "          aa_name=r\"^[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\"\n",
        "          aa_name=re.search(aa_name,t,flags=re.MULTILINE).group()\n",
        "      except AttributeError:\n",
        "          aa_name=r\"^[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\"\n",
        "          aa_name=re.search(aa_name,t,flags=re.MULTILINE).group()\n",
        "\n",
        "      #st.write(\"Name :\"+ aa_name)\n",
        "\n",
        "\n",
        "      if your_name==aa_name and your_no==aa_no:\n",
        "        aut=\"NO\"\n",
        "        ver=\"YES\"\n",
        "        df1(aa_name,aa_no,aut,ver)\n",
        "        st.error(\"The Document is Identified as Aadhaar Card and verified. But cannot authenticate due to blur image or QRcode is not available.  \\n  Please upload again...!\")\n",
        "            \n",
        "            \n",
        "      else:\n",
        "        aut=\"NO\"\n",
        "        ver=\"NO\"\n",
        "        df1(aa_name,aa_no,aut,ver)\n",
        "        st.error(\"The Document is Identified as Aadhaar Card, but not verified and authenticate.  \\n  Please verify again...!\")\n",
        "\n",
        "  @st.cache(suppress_st_warning=True)\n",
        "  def df1(aa_name,aa_no,aut,ver):\n",
        "    db = sqlite3.connect(\"testing_aa.db\")\n",
        "    #db.execute(\"drop table if exists result1\")\n",
        "    #st.write(aa_no)\n",
        "    try:\n",
        "        db.execute(\"create table result1(Name text, Aadhaar_No number ,Authenticate text, Verification text)\")\n",
        "    except:\n",
        "        print(\"Already table existed !!\")\n",
        "    cmd = \"insert into result1(Name, Aadhaar_No,Authenticate,Verification) values('{}','{}','{}','{}')\".format(aa_name,aa_no,aut,ver)\n",
        "    db.execute(cmd)\n",
        "    db.commit()\n",
        "    qry = \"\"\" SELECT * FROM result1 \"\"\"\n",
        "    df1 = pd.read_sql_query(qry, db)\n",
        "    st.write(df1.head())\n",
        "\n",
        "  @st.cache(suppress_st_warning=True)\n",
        "  def pan(result,img,your_name,your_no):\n",
        "    spacer = 100\n",
        "    t=\"\"\n",
        "    l=[\"INCOME\",\"TAX\",\"DEPARTMENT\",\"GOVT\",\"OF\",\"INDIA\",\"Permanent\",\"Account\",\"Number\"]\n",
        "    for detection in result: \n",
        "        top_left = tuple(detection[0][0])\n",
        "        bottom_right = tuple(detection[0][2])\n",
        "        text = detection[1]\n",
        "        try:\n",
        "          img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "          img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "        except:\n",
        "          pass\n",
        "        \n",
        "        spacer+=15\n",
        "        #print(text)\n",
        "        x=text.split(\" \")\n",
        "        c=0\n",
        "        for i in x:\n",
        "          if i in l:\n",
        "            c=1\n",
        "            break\n",
        "        if c==0:\n",
        "          t=t+text+\"\\n\"\n",
        "    #st.write(t)  \n",
        "    pan_pattern=r\"[A-Z]{5}\\d{4}[A-Z]\"\n",
        "    pan_name=r\"^[A-Z]+\\s[A-Z]+\\s[A-Z]+\\s\"\n",
        "    pan_no=re.search(pan_pattern,t).group()\n",
        "    try:\n",
        "      pan_name=re.search(pan_name,t,flags=re.MULTILINE).group()\n",
        "    except:\n",
        "      pan_name=r\"^[A-Z]+\\s[A-Z]+\\s\"\n",
        "      pan_name=re.search(pan_name,t,flags=re.MULTILINE).group()\n",
        "    pan_name=pan_name[:len(pan_name)-1]\n",
        "    #st.write(\"PAN Number :\"+pan_no)\n",
        "    #st.write(\"Name :\"+ pan_name)\n",
        "    \n",
        "    if your_name==pan_name and your_no==pan_no:\n",
        "      v_p=\"YES\"\n",
        "      df2(pan_name,pan_no,v_p)\n",
        "      st.success(\"The Document is Identified as PAN Card and verified successfully.\")\n",
        "      \n",
        "          \n",
        "          \n",
        "    else:\n",
        "      v_p=\"NO\"\n",
        "      df2(pan_name,pan_no,v_p)\n",
        "      st.error(\"The Document is Identified as PAN Card, but not verified.  \\n  Please verify again...!\")\n",
        "      \n",
        "\n",
        "  @st.cache(suppress_st_warning=True)\n",
        "  def df2(pan_name,pan_no,v_p):\n",
        "    db = sqlite3.connect(\"testing_pan.db\")\n",
        "    #db.execute(\"drop table if exists result2\")\n",
        "    try:\n",
        "        db.execute(\"create table result2(Name text, PAN_No varchar2(50), Verification text)\")\n",
        "    except:\n",
        "        print(\"Already table existed !!\")\n",
        "    cmd = \"insert into result2(Name, PAN_No, Verification) values('{}','{}','{}')\".format(pan_name,pan_no,v_p)\n",
        "    db.execute(cmd)\n",
        "    db.commit()\n",
        "    qry = \"\"\" SELECT * FROM result2 \"\"\"\n",
        "    df2 = pd.read_sql_query(qry, db)\n",
        "    st.write(df2.head())\n",
        "\n",
        "\n",
        "  @st.cache(suppress_st_warning=True)\n",
        "  def driving(result,img,your_name,your_no):\n",
        "\n",
        "    spacer = 100\n",
        "    t=\"\"\n",
        "    l=[]\n",
        "    f=0\n",
        "    for detection in result: \n",
        "        top_left = tuple(detection[0][0])\n",
        "        bottom_right = tuple(detection[0][2])\n",
        "        text = detection[1]\n",
        "        try:\n",
        "          img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "          img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "        except:\n",
        "          pass\n",
        "      \n",
        "        spacer+=15\n",
        "        #print(text)\n",
        "        x=text.split(\" \")\n",
        "        l.append(x)\n",
        "        t=t+text+\"\\n\"\n",
        "\n",
        "    if(['Name'] in l):\n",
        "      d_name=l[l.index(['Name'])+1]\n",
        "      d_name=' '.join(map(str,d_name))\n",
        "      #print(d_name)\n",
        "      #print(type(d_name))\n",
        "      f=1\n",
        "    d_pattern=r\"[A-Z]{2}\\w+\\s\\d\\w+\"\n",
        "    d_no=re.search(d_pattern,t).group()\n",
        "    \n",
        "    if f==0:\n",
        "      d_name=r\"^[A-Z]+\\s[A-Z]+\\s\"\n",
        "      d_name=re.search(d_name,t,flags=re.MULTILINE).group()\n",
        "    #st.write(\"Driving License Number :\"+d_no)\n",
        "    #st.write(\"Name :\"+ d_name)\n",
        "\n",
        "    if your_name==d_name and your_no==d_no:\n",
        "          v_d=\"YES\"\n",
        "          df3(d_name,d_no,v_d)\n",
        "          st.success(\"The Document is Identified as Driving License and verified successfully.\")\n",
        "          \n",
        "          \n",
        "    else:\n",
        "          v_d=\"NO\"\n",
        "          df3(d_name,d_no,v_d)\n",
        "          st.error(\"The Document is Identified as Driving License, but not verified.  \\n  Please verify again...!\")\n",
        "\n",
        "  @st.cache(suppress_st_warning=True)\n",
        "  def df3(d_name,d_no,v_d):\n",
        "    db = sqlite3.connect(\"testing_DL.db\")\n",
        "    #db.execute(\"drop table if exists result3\")\n",
        "    try:\n",
        "        db.execute(\"create table result3(Name text, Driving_License_No varchar2(50), Verification text)\")\n",
        "    except:\n",
        "        print(\"Already table existed !!\")\n",
        "    cmd = \"insert into result3(Name, Driving_License_No, Verification) values('{}','{}','{}')\".format(d_name,d_no,v_d)\n",
        "    db.execute(cmd)\n",
        "    db.commit()\n",
        "    qry = \"\"\" SELECT * FROM result3 \"\"\"\n",
        "    df3 = pd.read_sql_query(qry, db)\n",
        "    st.write(df3.head())\n",
        "\n",
        "  if uploaded_file is not None:\n",
        "\n",
        "          img = Image.open(uploaded_file)\n",
        "          catagories=['Aadhar card', 'Driving license', 'Pan card']\n",
        "          #st.write('Result...')\n",
        "          flat_data=[]\n",
        "          imgi=np.array(img)\n",
        "          img_resized=resize(imgi,(150,150,3))\n",
        "          flat_data.append(img_resized.flatten())\n",
        "          flat_data=np.array(flat_data)\n",
        "          y_out=model.predict(flat_data)\n",
        "          y_out=catagories[y_out[0]]\n",
        "          IMAGE_PATH = img\n",
        "          reader = easyocr.Reader(['en'])\n",
        "          result = reader.readtext(IMAGE_PATH)\n",
        "          \n",
        "                  \n",
        "          if y_out==\"Pan card\":\n",
        "              data = pan(result,imgi,your_name,your_no)\n",
        "          elif y_out==\"Aadhar card\":\n",
        "              data = aa(result,imgi,your_name,your_no)\n",
        "          else:\n",
        "              data = driving(result,imgi,your_name,your_no)\n",
        "      #st.success(\"Here you go!\")\n",
        "  else:\n",
        "      st.write(\"Upload an Image\")\n",
        "\n",
        "elif page == 'Multi-image File':\n",
        "\n",
        "  st.text('upload the Multi-image CSV File')\n",
        "\n",
        "  model=pickle.load(open('img_model.p','rb'))\n",
        "\n",
        "  dataset = st.file_uploader(\"upload file here\", type = ['csv'])\n",
        "  if dataset is not None:\n",
        "    df = pd.read_csv(dataset)\n",
        "\n",
        "    @st.cache(suppress_st_warning=True)\n",
        "    def aa(result,img,your_name,your_no):\n",
        "      decodedObjects = pyzbar.decode(img)\n",
        "      for obj in decodedObjects:\n",
        "        x=list(str(obj.data).split('\"'))\n",
        "        if(obj.type=='QRCODE'):\n",
        "          print(x[7],x[5])\n",
        "      try:\n",
        "        aa_name=x[7]\n",
        "        aa_no=x[5]\n",
        "        if (aa_name==your_name and aa_no==your_no):\n",
        "          aut=\"YES\"\n",
        "          ver=\"YES\"\n",
        "          #st.write(\"Aadhar Name:\"+ aa_name)\n",
        "          #st.write(\"Aadhar no:\"+ aa_no)\n",
        "          df1(aa_name,aa_no,aut,ver)\n",
        "          #st.success(\"The Document is Identified as Aadhaar Card and Authenticated successfully...!\")\n",
        "      except:    \n",
        "        spacer = 100\n",
        "        t=''\n",
        "        l=['Unique', 'Identification', 'Authority', 'of', 'India','Solapur', 'North','Father','Uniquue Identiic']\n",
        "        for detection in result: \n",
        "          top_left = tuple(detection[0][0])\n",
        "          bottom_right = tuple(detection[0][2])\n",
        "          text = detection[1]\n",
        "          try:\n",
        "            img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "            img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "          except:\n",
        "            pass   \n",
        "          spacer+=15\n",
        "          #print(text)\n",
        "          x=text.split(\" \")\n",
        "          c=0\n",
        "          for i in x:\n",
        "            if i in l:\n",
        "              c=1\n",
        "              break\n",
        "          if c==0:\n",
        "            t=t+text+\"\\n\"\n",
        "        aa_pattern=r\"\\d{4}\\s\\d{4}\\s\\d{4}\"\n",
        "        aa_no_=re.search(aa_pattern,t).group()\n",
        "        no=''\n",
        "        for i in aa_no_:\n",
        "          if(i!=\"\\n\" and i!=\" \"):\n",
        "              no=no+i\n",
        "        aa_no=no\n",
        "        #st.write(\"Aadhar Number :\"+ no)\n",
        "        try:\n",
        "            aa_name=r\"^[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\"\n",
        "            aa_name=re.search(aa_name,t,flags=re.MULTILINE).group()\n",
        "        except AttributeError:\n",
        "            aa_name=r\"^[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\"\n",
        "            aa_name=re.search(aa_name,t,flags=re.MULTILINE).group()\n",
        "\n",
        "        #st.write(\"Name :\"+ aa_name)\n",
        "\n",
        "        if your_name==aa_name and your_no==aa_no:\n",
        "          aut=\"NO\"\n",
        "          ver=\"YES\"\n",
        "          df1(aa_name,aa_no,aut,ver)\n",
        "          #st.error(\"The Document is Identified as Aadhaar Card and verified. But cannot authenticate due to blur image or QRcode is not available.  \\n  Please upload again...!\")\n",
        "              \n",
        "        else:\n",
        "          aut=\"NO\"\n",
        "          ver=\"NO\"\n",
        "          df1(aa_name,aa_no,aut,ver)\n",
        "          #st.error(\"The Document is Identified as Aadhaar Card, but not verified and authenticate.  \\n  Please verify again...!\")\n",
        "\n",
        "    @st.cache(suppress_st_warning=True)\n",
        "    def df1(aa_name,aa_no,aut,ver):\n",
        "      db = sqlite3.connect(\"multi_testing_aa.db\")\n",
        "      #db.execute(\"drop table if exists result\")\n",
        "      #st.write(aa_no)\n",
        "      try:\n",
        "          db.execute(\"create table result11(Name text, Aadhaar_No number ,Authenticate text, Verification text)\")\n",
        "      except:\n",
        "          print(\"Already table existed !!\")\n",
        "      cmd = \"insert into result11(Name, Aadhaar_No,Authenticate,Verification) values('{}','{}','{}','{}')\".format(aa_name,aa_no,aut,ver)\n",
        "      db.execute(cmd)\n",
        "      db.commit()\n",
        "      \n",
        "\n",
        "    @st.cache(suppress_st_warning=True)\n",
        "    def pan(result,img,your_name,your_no):\n",
        "      spacer = 100\n",
        "      t=\"\"\n",
        "      l=[\"INCOME\",\"TAX\",\"DEPARTMENT\",\"GOVT\",\"OF\",\"INDIA\",\"Permanent\",\"Account\",\"Number\"]\n",
        "      for detection in result: \n",
        "          top_left = tuple(detection[0][0])\n",
        "          bottom_right = tuple(detection[0][2])\n",
        "          text = detection[1]\n",
        "          try:\n",
        "            img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "            img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "          except:\n",
        "            pass\n",
        "          \n",
        "          spacer+=15\n",
        "          #print(text)\n",
        "          x=text.split(\" \")\n",
        "          c=0\n",
        "          for i in x:\n",
        "            if i in l:\n",
        "              c=1\n",
        "              break\n",
        "          if c==0:\n",
        "            t=t+text+\"\\n\"\n",
        "      #st.write(t)  \n",
        "      pan_pattern=r\"[A-Z]{5}\\d{4}[A-Z]\"\n",
        "      pan_name=r\"^[A-Z]+\\s[A-Z]+\\s[A-Z]+\\s\"\n",
        "      pan_no=re.search(pan_pattern,t).group()\n",
        "      try:\n",
        "        pan_name=re.search(pan_name,t,flags=re.MULTILINE).group()\n",
        "      except:\n",
        "        pan_name=r\"^[A-Z]+\\s[A-Z]+\\s\"\n",
        "        pan_name=re.search(pan_name,t,flags=re.MULTILINE).group()\n",
        "      pan_name=pan_name[:len(pan_name)-1]\n",
        "      #st.write(\"PAN Number :\"+pan_no)\n",
        "      #st.write(\"Name :\"+ pan_name)\n",
        "      \n",
        "      if your_name==pan_name and your_no==pan_no:\n",
        "        v_p=\"YES\"\n",
        "        df2(pan_name,pan_no,v_p)\n",
        "        #st.success(\"The Document is Identified as PAN Card and verified successfully.\")\n",
        "        \n",
        "            \n",
        "            \n",
        "      else:\n",
        "        v_p=\"NO\"\n",
        "        df2(pan_name,pan_no,v_p)\n",
        "        #st.error(\"The Document is Identified as PAN Card, but not verified.  \\n  Please verify again...!\")\n",
        "        \n",
        "\n",
        "    @st.cache(suppress_st_warning=True)\n",
        "    def df2(pan_name,pan_no,v_p):\n",
        "      db = sqlite3.connect(\"multi_testing_pan.db\")\n",
        "      #db.execute(\"drop table if exists result\")\n",
        "      try:\n",
        "          db.execute(\"create table result22(Name text, PAN_No varchar2(50), Verification text)\")\n",
        "      except:\n",
        "          print(\"Already table existed !!\")\n",
        "      cmd = \"insert into result22(Name, PAN_No, Verification) values('{}','{}','{}')\".format(pan_name,pan_no,v_p)\n",
        "      db.execute(cmd)\n",
        "      db.commit()\n",
        "      \n",
        "\n",
        "\n",
        "    @st.cache(suppress_st_warning=True)\n",
        "    def driving(result,img,your_name,your_no):\n",
        "\n",
        "      spacer = 100\n",
        "      t=\"\"\n",
        "      l=[]\n",
        "      f=0\n",
        "      for detection in result: \n",
        "          top_left = tuple(detection[0][0])\n",
        "          bottom_right = tuple(detection[0][2])\n",
        "          text = detection[1]\n",
        "          try:\n",
        "            img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "            img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "          except:\n",
        "            pass\n",
        "        \n",
        "          spacer+=15\n",
        "          #print(text)\n",
        "          x=text.split(\" \")\n",
        "          l.append(x)\n",
        "          t=t+text+\"\\n\"\n",
        "\n",
        "      if(['Name'] in l):\n",
        "        d_name=l[l.index(['Name'])+1]\n",
        "        d_name=' '.join(map(str,d_name))\n",
        "        #print(d_name)\n",
        "        #print(type(d_name))\n",
        "        f=1\n",
        "      d_pattern=r\"[A-Z]{2}\\w+\\s\\d\\w+\"\n",
        "      d_no=re.search(d_pattern,t).group()\n",
        "      \n",
        "      if f==0:\n",
        "        d_name=r\"^[A-Z]+\\s[A-Z]+\\s\"\n",
        "        d_name=re.search(d_name,t,flags=re.MULTILINE).group()\n",
        "      #st.write(\"Driving License Number :\"+d_no)\n",
        "      #st.write(\"Name :\"+ d_name)\n",
        "\n",
        "      if your_name==d_name and your_no==d_no:\n",
        "            v_d=\"YES\"\n",
        "            df3(d_name,d_no,v_d)\n",
        "            #st.success(\"The Document is Identified as Driving License and verified successfully.\")\n",
        "            \n",
        "            \n",
        "      else:\n",
        "            v_d=\"NO\"\n",
        "            df3(d_name,d_no,v_d)\n",
        "            #st.error(\"The Document is Identified as Driving License, but not verified.  \\n  Please verify again...!\")\n",
        "\n",
        "    @st.cache(suppress_st_warning=True)\n",
        "    def df3(d_name,d_no,v_d):\n",
        "      db = sqlite3.connect(\"multi_testing_DL.db\")\n",
        "      #db.execute(\"drop table if exists result\")\n",
        "      try:\n",
        "          db.execute(\"create table result33(Name text, Driving_License_No varchar2(50), Verification text)\")\n",
        "      except:\n",
        "          print(\"Already table existed !!\")\n",
        "      cmd = \"insert into result33(Name, Driving_License_No, Verification) values('{}','{}','{}')\".format(d_name,d_no,v_d)\n",
        "      db.execute(cmd)\n",
        "      db.commit()\n",
        "      \n",
        "    #reader = csv.reader(df)\n",
        "    #st.write(len(df))\n",
        "    if df is not None:\n",
        "            for i in range(len(df)):\n",
        "              img = Image.open(df.loc[i][2])\n",
        "              #st.image(image, use_column_width=True)\n",
        "              #st.write(df.loc[i][2])\n",
        "              catagories=['Aadhar card', 'Driving license', 'Pan card']\n",
        "              #st.write('Result...')\n",
        "              flat_data=[]\n",
        "              imgi=np.array(img)\n",
        "              img_resized=resize(imgi,(150,150,3))\n",
        "              flat_data.append(img_resized.flatten())\n",
        "              flat_data=np.array(flat_data)\n",
        "              y_out=model.predict(flat_data)\n",
        "              y_out=catagories[y_out[0]]\n",
        "              IMAGE_PATH = img\n",
        "              reader = easyocr.Reader(['en'])\n",
        "              result = reader.readtext(IMAGE_PATH)\n",
        "            \n",
        "              your_name=df.loc[i][0]\n",
        "              your_no=str(df.loc[i][1])    \n",
        "              if y_out==\"Pan card\":\n",
        "                  data = pan(result,imgi,your_name,your_no)\n",
        "              elif y_out==\"Aadhar card\":\n",
        "                  data = aa(result,imgi,your_name,your_no)\n",
        "              else:\n",
        "                  data = driving(result,imgi,your_name,your_no)\n",
        "            try:\n",
        "              db = sqlite3.connect(\"multi_testing_aa.db\")\n",
        "              qry = \"\"\" SELECT * FROM result11 \"\"\"\n",
        "              df1 = pd.read_sql_query(qry, db)\n",
        "              st.write(df1.head())\n",
        "              db.execute(\"drop table if exists result11\")\n",
        "            except:\n",
        "                pass\n",
        "            try:\n",
        "              db = sqlite3.connect(\"multi_testing_pan.db\")\n",
        "              qry = \"\"\" SELECT * FROM result22 \"\"\"\n",
        "              df2 = pd.read_sql_query(qry, db)\n",
        "              st.write(df2.head())\n",
        "              db.execute(\"drop table if exists result22\")\n",
        "            except:\n",
        "              pass\n",
        "            try:\n",
        "              db = sqlite3.connect(\"multi_testing_DL.db\")\n",
        "              qry = \"\"\" SELECT * FROM result33 \"\"\"\n",
        "              df3 = pd.read_sql_query(qry, db)\n",
        "              st.write(df3.head())\n",
        "              db.execute(\"drop table if exists result33\")\n",
        "            except:\n",
        "              pass\n",
        "\n",
        "    else:\n",
        "        st.write(\"Upload an Image\")\n",
        "\n",
        "else:\n",
        "    st.write(\"good bye\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FBHwd0mExBo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ddf8c7-52e6-4209-8fa9-8312f57233c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "JMRNIxeVHa40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18b55c2-8740-4e52-91ed-9a86a1037785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-01 05:57:30.868 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.303s\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.134.173.73:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://green-walrus-25.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import json\n",
        "import easyocr\n",
        "from matplotlib import pyplot as plt\n",
        "import tkinter\n",
        "from tkinter import font\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from PIL import Image\n",
        "import io\n",
        "import streamlit as st\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import pickle\n",
        "import re\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import pyzbar.pyzbar as pyzbar\n",
        "from pyzbar.pyzbar import decode\n",
        "\n",
        "\n",
        "\n",
        "st.title('Image classifier and text extraction using ML')\n",
        "st.text('upload the Image for identification')\n",
        "\n",
        "model=pickle.load(open('img_model.p','rb'))\n",
        "\n",
        "your_name = st.text_input(\"Enter your Name\")\n",
        "st.title(your_name)\n",
        "your_no = st.text_input(\"Enter your Document Number\")\n",
        "st.title(your_no)\n",
        "\n",
        "uploaded_file= st.file_uploader(\"choose an image...\",type=['jpeg','jpg','png'])\n",
        "\n",
        "#title\n",
        "st.title('Extraction and verification of document')\n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def aa(result,img,your_name,your_no):\n",
        "  decodedObjects = pyzbar.decode(img)\n",
        "  for obj in decodedObjects:\n",
        "    x=list(str(obj.data).split('\"'))\n",
        "    if(obj.type=='QRCODE'):\n",
        "      print(x[7],x[5])\n",
        "  try:\n",
        "    aa_name=x[7]\n",
        "    aa_no=x[5]\n",
        "    if (aa_name==your_name and aa_no==your_no):\n",
        "      aut=\"YES\"\n",
        "      ver=\"YES\"\n",
        "      st.write(\"Aadhar Name:\"+ aa_name)\n",
        "      st.write(\"Aadhar no:\"+ aa_no)\n",
        "      df1(aa_name,aa_no,aut,ver)\n",
        "      st.success(\"The Document is Identified as Aadhaar Card and Authenticated successfully...!\")\n",
        "  except:    \n",
        "    spacer = 100\n",
        "    t=''\n",
        "    l=['Unique', 'Identification', 'Authority', 'of', 'India','Solapur', 'North','Father']\n",
        "    for detection in result: \n",
        "      top_left = tuple(detection[0][0])\n",
        "      bottom_right = tuple(detection[0][2])\n",
        "      text = detection[1]\n",
        "      try:\n",
        "        img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "        img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "      except:\n",
        "        pass\n",
        "      \n",
        "      \n",
        "      spacer+=15\n",
        "      #print(text)\n",
        "\n",
        "      x=text.split(\" \")\n",
        "      c=0\n",
        "      for i in x:\n",
        "        if i in l:\n",
        "          c=1\n",
        "          break\n",
        "      if c==0:\n",
        "        t=t+text+\"\\n\"\n",
        "\n",
        "    aa_pattern=r\"\\d{4}\\s\\d{4}\\s\\d{4}\"\n",
        "    aa_no_=re.search(aa_pattern,t).group()\n",
        "    no=''\n",
        "    for i in aa_no_:\n",
        "      if(i!=\"\\n\" and i!=\" \"):\n",
        "          no=no+i\n",
        "    aa_no=no\n",
        "    st.write(\"Aadhar Number :\"+ no)\n",
        "\n",
        "\n",
        "    try:\n",
        "        aa_name=r\"^[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\"\n",
        "        aa_name=re.search(aa_name,t,flags=re.MULTILINE).group()\n",
        "    except AttributeError:\n",
        "        aa_name=r\"^[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\"\n",
        "        aa_name=re.search(aa_name,t,flags=re.MULTILINE).group()\n",
        "\n",
        "    st.write(\"Name :\"+ aa_name)\n",
        "\n",
        "\n",
        "    if your_name==aa_name and your_no==aa_no:\n",
        "      aut=\"NO\"\n",
        "      ver=\"YES\"\n",
        "      df1(aa_name,aa_no,aut,ver)\n",
        "      st.error(\"The Document is Identified as Aadhaar Card and verified. But cannot authenticate due to blur image or QRcode is not available.  \\n  Please upload again...!\")\n",
        "          \n",
        "          \n",
        "    else:\n",
        "      aut=\"NO\"\n",
        "      ver=\"NO\"\n",
        "      df1(aa_name,aa_no,aut,ver)\n",
        "      st.error(\"The Document is Identified as Aadhaar Card, but not verified and authenticate.  \\n  Please verify again...!\")\n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def df1(aa_name,aa_no,aut,ver):\n",
        "  db = sqlite3.connect(\"testing_aa.db\")\n",
        "  #db.execute(\"drop table if exists result\")\n",
        "  #st.write(aa_no)\n",
        "  try:\n",
        "      db.execute(\"create table result1(Name text, Aadhaar_No number ,Authenticate text, Verification text)\")\n",
        "  except:\n",
        "      print(\"Already table existed !!\")\n",
        "  cmd = \"insert into result1(Name, Aadhaar_No,Authenticate,Verification) values('{}','{}','{}','{}')\".format(aa_name,aa_no,aut,ver)\n",
        "  db.execute(cmd)\n",
        "  db.commit()\n",
        "  qry = \"\"\" SELECT * FROM result1 \"\"\"\n",
        "  df1 = pd.read_sql_query(qry, db)\n",
        "  st.write(df1.head())\n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def pan(result,img,your_name,your_no):\n",
        "  spacer = 100\n",
        "  t=\"\"\n",
        "  l=[\"INCOME\",\"TAX\",\"DEPARTMENT\",\"GOVT\",\"OF\",\"INDIA\",\"Permanent\",\"Account\",\"Number\"]\n",
        "  for detection in result: \n",
        "      top_left = tuple(detection[0][0])\n",
        "      bottom_right = tuple(detection[0][2])\n",
        "      text = detection[1]\n",
        "      try:\n",
        "        img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "        img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "      except:\n",
        "        pass\n",
        "      \n",
        "      spacer+=15\n",
        "      #print(text)\n",
        "      x=text.split(\" \")\n",
        "      c=0\n",
        "      for i in x:\n",
        "        if i in l:\n",
        "          c=1\n",
        "          break\n",
        "      if c==0:\n",
        "        t=t+text+\"\\n\"\n",
        "  #st.write(t)  \n",
        "  pan_pattern=r\"[A-Z]{5}\\d{4}[A-Z]\"\n",
        "  pan_name=r\"^[A-Z]+\\s[A-Z]+\\s[A-Z]+\\s\"\n",
        "  pan_no=re.search(pan_pattern,t).group()\n",
        "  try:\n",
        "    pan_name=re.search(pan_name,t,flags=re.MULTILINE).group()\n",
        "  except:\n",
        "    pan_name=r\"^[A-Z]+\\s[A-Z]+\\s\"\n",
        "    pan_name=re.search(pan_name,t,flags=re.MULTILINE).group()\n",
        "  pan_name=pan_name[:len(pan_name)-1]\n",
        "  st.write(\"PAN Number :\"+pan_no)\n",
        "  st.write(\"Name :\"+ pan_name)\n",
        "  \n",
        "  if your_name==pan_name and your_no==pan_no:\n",
        "    v_p=\"YES\"\n",
        "    df2(pan_name,pan_no,v_p)\n",
        "    st.success(\"The Document is Identified as PAN Card and verified successfully.\")\n",
        "    \n",
        "        \n",
        "        \n",
        "  else:\n",
        "    v_p=\"NO\"\n",
        "    df2(pan_name,pan_no,v_p)\n",
        "    st.error(\"The Document is Identified as PAN Card, but not verified.  \\n  Please verify again...!\")\n",
        "    \n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def df2(pan_name,pan_no,v_p):\n",
        "  db = sqlite3.connect(\"testing_pan.db\")\n",
        "  #db.execute(\"drop table if exists result\")\n",
        "  try:\n",
        "      db.execute(\"create table result2(Name text, PAN_No varchar2(50), Verification text)\")\n",
        "  except:\n",
        "      print(\"Already table existed !!\")\n",
        "  cmd = \"insert into result2(Name, PAN_No, Verification) values('{}','{}','{}')\".format(pan_name,pan_no,v_p)\n",
        "  db.execute(cmd)\n",
        "  db.commit()\n",
        "  qry = \"\"\" SELECT * FROM result2 \"\"\"\n",
        "  df2 = pd.read_sql_query(qry, db)\n",
        "  st.write(df2.head())\n",
        "\n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def driving(result,img,your_name,your_no):\n",
        "\n",
        "  spacer = 100\n",
        "  t=\"\"\n",
        "  l=[]\n",
        "  f=0\n",
        "  for detection in result: \n",
        "      top_left = tuple(detection[0][0])\n",
        "      bottom_right = tuple(detection[0][2])\n",
        "      text = detection[1]\n",
        "      try:\n",
        "        img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "        img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "      except:\n",
        "        pass\n",
        "     \n",
        "      spacer+=15\n",
        "      #print(text)\n",
        "      x=text.split(\" \")\n",
        "      l.append(x)\n",
        "      t=t+text+\"\\n\"\n",
        "\n",
        "  if(['Name'] in l):\n",
        "    d_name=l[l.index(['Name'])+1]\n",
        "    d_name=' '.join(map(str,d_name))\n",
        "    #print(d_name)\n",
        "    #print(type(d_name))\n",
        "    f=1\n",
        "  d_pattern=r\"[A-Z]{2}\\w+\\s\\d\\w+\"\n",
        "  d_no=re.search(d_pattern,t).group()\n",
        "  \n",
        "  if f==0:\n",
        "    d_name=r\"^[A-Z]+\\s[A-Z]+\\s\"\n",
        "    d_name=re.search(d_name,t,flags=re.MULTILINE).group()\n",
        "  st.write(\"Driving License Number :\"+d_no)\n",
        "  st.write(\"Name :\"+ d_name)\n",
        "\n",
        "  if your_name==d_name and your_no==d_no:\n",
        "        v_d=\"YES\"\n",
        "        df3(d_name,d_no,v_d)\n",
        "        st.success(\"The Document is Identified as Driving License and verified successfully.\")\n",
        "        \n",
        "        \n",
        "  else:\n",
        "        v_d=\"NO\"\n",
        "        df3(d_name,d_no,v_d)\n",
        "        st.error(\"The Document is Identified as Driving License, but not verified.  \\n  Please verify again...!\")\n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def df3(d_name,d_no,v_d):\n",
        "  db = sqlite3.connect(\"testing_DL.db\")\n",
        "  #db.execute(\"drop table if exists result\")\n",
        "  try:\n",
        "      db.execute(\"create table result3(Name text, Driving_License_No varchar2(50), Verification text)\")\n",
        "  except:\n",
        "      print(\"Already table existed !!\")\n",
        "  cmd = \"insert into result3(Name, Driving_License_No, Verification) values('{}','{}','{}')\".format(d_name,d_no,v_d)\n",
        "  db.execute(cmd)\n",
        "  db.commit()\n",
        "  qry = \"\"\" SELECT * FROM result3 \"\"\"\n",
        "  df3 = pd.read_sql_query(qry, db)\n",
        "  st.write(df3.head())\n",
        "\n",
        "if uploaded_file is not None:\n",
        "\n",
        "        img = Image.open(uploaded_file)\n",
        "        catagories=['Aadhar card', 'Driving license', 'Pan card']\n",
        "        #st.write('Result...')\n",
        "        flat_data=[]\n",
        "        imgi=np.array(img)\n",
        "        img_resized=resize(imgi,(150,150,3))\n",
        "        flat_data.append(img_resized.flatten())\n",
        "        flat_data=np.array(flat_data)\n",
        "        y_out=model.predict(flat_data)\n",
        "        y_out=catagories[y_out[0]]\n",
        "        IMAGE_PATH = img\n",
        "        reader = easyocr.Reader(['en'])\n",
        "        result = reader.readtext(IMAGE_PATH)\n",
        "        \n",
        "                \n",
        "        if y_out==\"Pan card\":\n",
        "            data = pan(result,imgi,your_name,your_no)\n",
        "        elif y_out==\"Aadhar card\":\n",
        "            data = aa(result,imgi,your_name,your_no)\n",
        "        else:\n",
        "            data = driving(result,imgi,your_name,your_no)\n",
        "    #st.success(\"Here you go!\")\n",
        "else:\n",
        "    st.write(\"Upload an Image\")\n",
        "\n",
        "#db = sqlite3.connect(\"testing_aa.db\")\n",
        "#db.execute(\"drop table if exists result1\")\n",
        "#db = sqlite3.connect(\"testing_pan.db\")\n",
        "#db.execute(\"drop table if exists result2\")\n",
        "#db = sqlite3.connect(\"testing_DL.db\")\n",
        "#db.execute(\"drop table if exists result3\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bPgGaC9ADEOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca761e0-bc0c-4a9a-9ceb-f92c652fd04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import json\n",
        "import easyocr\n",
        "from matplotlib import pyplot as plt\n",
        "import tkinter\n",
        "from tkinter import font\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from PIL import Image\n",
        "import io\n",
        "import streamlit as st\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import pickle\n",
        "import re\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import pyzbar.pyzbar as pyzbar\n",
        "from pyzbar.pyzbar import decode\n",
        "\n",
        "\n",
        "\n",
        "st.title('Image classifier and text extraction using ML')\n",
        "st.text('upload the Image for identification')\n",
        "\n",
        "model=pickle.load(open('img_model.p','rb'))\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/APD.csv\")\n",
        "\n",
        "\n",
        "#title\n",
        "st.title('Extraction and verification of document')\n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def aa(result,img,your_name,your_no):\n",
        "  decodedObjects = pyzbar.decode(img)\n",
        "  for obj in decodedObjects:\n",
        "    x=list(str(obj.data).split('\"'))\n",
        "    if(obj.type=='QRCODE'):\n",
        "      print(x[7],x[5])\n",
        "  try:\n",
        "    aa_name=x[7]\n",
        "    aa_no=x[5]\n",
        "    if (aa_name==your_name and aa_no==your_no):\n",
        "      aut=\"YES\"\n",
        "      ver=\"YES\"\n",
        "      st.write(\"Aadhar Name:\"+ aa_name)\n",
        "      st.write(\"Aadhar no:\"+ aa_no)\n",
        "      df1(aa_name,aa_no,aut,ver)\n",
        "      st.success(\"The Document is Identified as Aadhaar Card and Authenticated successfully...!\")\n",
        "  except:    \n",
        "    spacer = 100\n",
        "    t=''\n",
        "    l=['Unique', 'Identification', 'Authority', 'of', 'India','Solapur', 'North','Father','Uniquue Identiic']\n",
        "    for detection in result: \n",
        "      top_left = tuple(detection[0][0])\n",
        "      bottom_right = tuple(detection[0][2])\n",
        "      text = detection[1]\n",
        "      try:\n",
        "        img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "        img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "      except:\n",
        "        pass\n",
        "      \n",
        "      \n",
        "      spacer+=15\n",
        "      #print(text)\n",
        "\n",
        "      x=text.split(\" \")\n",
        "      c=0\n",
        "      for i in x:\n",
        "        if i in l:\n",
        "          c=1\n",
        "          break\n",
        "      if c==0:\n",
        "        t=t+text+\"\\n\"\n",
        "\n",
        "    aa_pattern=r\"\\d{4}\\s\\d{4}\\s\\d{4}\"\n",
        "    aa_no_=re.search(aa_pattern,t).group()\n",
        "    no=''\n",
        "    for i in aa_no_:\n",
        "      if(i!=\"\\n\" and i!=\" \"):\n",
        "          no=no+i\n",
        "    aa_no=no\n",
        "    st.write(\"Aadhar Number :\"+ no)\n",
        "\n",
        "\n",
        "    try:\n",
        "        aa_name=r\"^[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\"\n",
        "        aa_name=re.search(aa_name,t,flags=re.MULTILINE).group()\n",
        "    except AttributeError:\n",
        "        aa_name=r\"^[A-Z][a-z]\\w+\\s[A-Z][a-z]\\w+\"\n",
        "        aa_name=re.search(aa_name,t,flags=re.MULTILINE).group()\n",
        "\n",
        "    st.write(\"Name :\"+ aa_name)\n",
        "\n",
        "\n",
        "    if your_name==aa_name and your_no==aa_no:\n",
        "      aut=\"NO\"\n",
        "      ver=\"YES\"\n",
        "      df1(aa_name,aa_no,aut,ver)\n",
        "      st.error(\"The Document is Identified as Aadhaar Card and verified. But cannot authenticate due to blur image or QRcode is not available.  \\n  Please upload again...!\")\n",
        "          \n",
        "          \n",
        "    else:\n",
        "      aut=\"NO\"\n",
        "      ver=\"NO\"\n",
        "      df1(aa_name,aa_no,aut,ver)\n",
        "      st.error(\"The Document is Identified as Aadhaar Card, but not verified and authenticate.  \\n  Please verify again...!\")\n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def df1(aa_name,aa_no,aut,ver):\n",
        "  db = sqlite3.connect(\"testing_aa.db\")\n",
        "  #db.execute(\"drop table if exists result\")\n",
        "  #st.write(aa_no)\n",
        "  try:\n",
        "      db.execute(\"create table result1(Name text, Aadhaar_No number ,Authenticate text, Verification text)\")\n",
        "  except:\n",
        "      print(\"Already table existed !!\")\n",
        "  cmd = \"insert into result1(Name, Aadhaar_No,Authenticate,Verification) values('{}','{}','{}','{}')\".format(aa_name,aa_no,aut,ver)\n",
        "  db.execute(cmd)\n",
        "  db.commit()\n",
        "  \n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def pan(result,img,your_name,your_no):\n",
        "  spacer = 100\n",
        "  t=\"\"\n",
        "  l=[\"INCOME\",\"TAX\",\"DEPARTMENT\",\"GOVT\",\"OF\",\"INDIA\",\"Permanent\",\"Account\",\"Number\"]\n",
        "  for detection in result: \n",
        "      top_left = tuple(detection[0][0])\n",
        "      bottom_right = tuple(detection[0][2])\n",
        "      text = detection[1]\n",
        "      try:\n",
        "        img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "        img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "      except:\n",
        "        pass\n",
        "      \n",
        "      spacer+=15\n",
        "      #print(text)\n",
        "      x=text.split(\" \")\n",
        "      c=0\n",
        "      for i in x:\n",
        "        if i in l:\n",
        "          c=1\n",
        "          break\n",
        "      if c==0:\n",
        "        t=t+text+\"\\n\"\n",
        "  #st.write(t)  \n",
        "  pan_pattern=r\"[A-Z]{5}\\d{4}[A-Z]\"\n",
        "  pan_name=r\"^[A-Z]+\\s[A-Z]+\\s[A-Z]+\\s\"\n",
        "  pan_no=re.search(pan_pattern,t).group()\n",
        "  try:\n",
        "    pan_name=re.search(pan_name,t,flags=re.MULTILINE).group()\n",
        "  except:\n",
        "    pan_name=r\"^[A-Z]+\\s[A-Z]+\\s\"\n",
        "    pan_name=re.search(pan_name,t,flags=re.MULTILINE).group()\n",
        "  pan_name=pan_name[:len(pan_name)-1]\n",
        "  st.write(\"PAN Number :\"+pan_no)\n",
        "  st.write(\"Name :\"+ pan_name)\n",
        "  \n",
        "  if your_name==pan_name and your_no==pan_no:\n",
        "    v_p=\"YES\"\n",
        "    df2(pan_name,pan_no,v_p)\n",
        "    st.success(\"The Document is Identified as PAN Card and verified successfully.\")\n",
        "    \n",
        "        \n",
        "        \n",
        "  else:\n",
        "    v_p=\"NO\"\n",
        "    df2(pan_name,pan_no,v_p)\n",
        "    st.error(\"The Document is Identified as PAN Card, but not verified.  \\n  Please verify again...!\")\n",
        "    \n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def df2(pan_name,pan_no,v_p):\n",
        "  db = sqlite3.connect(\"testing_pan.db\")\n",
        "  #db.execute(\"drop table if exists result\")\n",
        "  try:\n",
        "      db.execute(\"create table result2(Name text, PAN_No varchar2(50), Verification text)\")\n",
        "  except:\n",
        "      print(\"Already table existed !!\")\n",
        "  cmd = \"insert into result2(Name, PAN_No, Verification) values('{}','{}','{}')\".format(pan_name,pan_no,v_p)\n",
        "  db.execute(cmd)\n",
        "  db.commit()\n",
        "  \n",
        "\n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def driving(result,img,your_name,your_no):\n",
        "\n",
        "  spacer = 100\n",
        "  t=\"\"\n",
        "  l=[]\n",
        "  f=0\n",
        "  for detection in result: \n",
        "      top_left = tuple(detection[0][0])\n",
        "      bottom_right = tuple(detection[0][2])\n",
        "      text = detection[1]\n",
        "      try:\n",
        "        img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "        img = cv2.putText(img,text,(20,spacer), font, 0.5,(0,255,0),2,cv2.LINE_AA)\n",
        "      except:\n",
        "        pass\n",
        "     \n",
        "      spacer+=15\n",
        "      #print(text)\n",
        "      x=text.split(\" \")\n",
        "      l.append(x)\n",
        "      t=t+text+\"\\n\"\n",
        "\n",
        "  if(['Name'] in l):\n",
        "    d_name=l[l.index(['Name'])+1]\n",
        "    d_name=' '.join(map(str,d_name))\n",
        "    #print(d_name)\n",
        "    #print(type(d_name))\n",
        "    f=1\n",
        "  d_pattern=r\"[A-Z]{2}\\w+\\s\\d\\w+\"\n",
        "  d_no=re.search(d_pattern,t).group()\n",
        "  \n",
        "  if f==0:\n",
        "    d_name=r\"^[A-Z]+\\s[A-Z]+\\s\"\n",
        "    d_name=re.search(d_name,t,flags=re.MULTILINE).group()\n",
        "  st.write(\"Driving License Number :\"+d_no)\n",
        "  st.write(\"Name :\"+ d_name)\n",
        "\n",
        "  if your_name==d_name and your_no==d_no:\n",
        "        v_d=\"YES\"\n",
        "        df3(d_name,d_no,v_d)\n",
        "        st.success(\"The Document is Identified as Driving License and verified successfully.\")\n",
        "        \n",
        "        \n",
        "  else:\n",
        "        v_d=\"NO\"\n",
        "        df3(d_name,d_no,v_d)\n",
        "        st.error(\"The Document is Identified as Driving License, but not verified.  \\n  Please verify again...!\")\n",
        "\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def df3(d_name,d_no,v_d):\n",
        "  db = sqlite3.connect(\"testing_DL.db\")\n",
        "  #db.execute(\"drop table if exists result\")\n",
        "  try:\n",
        "      db.execute(\"create table result3(Name text, Driving_License_No varchar2(50), Verification text)\")\n",
        "  except:\n",
        "      print(\"Already table existed !!\")\n",
        "  cmd = \"insert into result3(Name, Driving_License_No, Verification) values('{}','{}','{}')\".format(d_name,d_no,v_d)\n",
        "  db.execute(cmd)\n",
        "  db.commit()\n",
        "  \n",
        "\n",
        "if df is not None:\n",
        "        for i in range(9):\n",
        "          img = Image.open(df.loc[i][2])\n",
        "          #st.image(image, use_column_width=True)\n",
        "          #st.write(df.loc[i][2])\n",
        "          catagories=['Aadhar card', 'Driving license', 'Pan card']\n",
        "          #st.write('Result...')\n",
        "          flat_data=[]\n",
        "          imgi=np.array(img)\n",
        "          img_resized=resize(imgi,(150,150,3))\n",
        "          flat_data.append(img_resized.flatten())\n",
        "          flat_data=np.array(flat_data)\n",
        "          y_out=model.predict(flat_data)\n",
        "          y_out=catagories[y_out[0]]\n",
        "          IMAGE_PATH = img\n",
        "          reader = easyocr.Reader(['en'])\n",
        "          result = reader.readtext(IMAGE_PATH)\n",
        "        \n",
        "          your_name=df.loc[i][0]\n",
        "          your_no=str(df.loc[i][1])  \n",
        "          st.write(your_name,your_no)   \n",
        "          if y_out==\"Pan card\":\n",
        "              data = pan(result,imgi,your_name,your_no)\n",
        "          elif y_out==\"Aadhar card\":\n",
        "              data = aa(result,imgi,your_name,your_no)\n",
        "          else:\n",
        "              data = driving(result,imgi,your_name,your_no)\n",
        "        try:\n",
        "          db = sqlite3.connect(\"testing_aa.db\")\n",
        "          qry = \"\"\" SELECT * FROM result1 \"\"\"\n",
        "          df1 = pd.read_sql_query(qry, db)\n",
        "          st.write(df1.head())\n",
        "          db.execute(\"drop table if exists result1\")\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "          db = sqlite3.connect(\"testing_pan.db\")\n",
        "          qry = \"\"\" SELECT * FROM result2 \"\"\"\n",
        "          df2 = pd.read_sql_query(qry, db)\n",
        "          st.write(df2.head())\n",
        "          db.execute(\"drop table if exists result2\")\n",
        "        except:\n",
        "          pass\n",
        "        try:\n",
        "          db = sqlite3.connect(\"testing_DL.db\")\n",
        "          qry = \"\"\" SELECT * FROM result3 \"\"\"\n",
        "          df3 = pd.read_sql_query(qry, db)\n",
        "          st.write(df3.head())\n",
        "          db.execute(\"drop table if exists result3\")\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "else:\n",
        "    st.write(\"Upload an Image\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f7ujCa1iNUaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92eef42c-7c9e-44f5-b618-4d903f4f5c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aV65sbw6qBkb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}